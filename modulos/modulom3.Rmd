---
title:  "Análisis de Regresión"
output:
  html_document:
    css: !expr here::here("styles/styles.css")
    toc: true
    toc_depth:  3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options("yaml.eval.expr" = TRUE)
```

# 3.3.Análisis de Regresión  

En el análisis de regresión se busca un modelo para describir estadísticamente la relación entre una __variable dependiente__ y otra (u otras) __independiente__.  El modelo es una ecuación matemática que "cuantifica" la relación entre las variables.  A la variable dependiente también se le llama __variable respuesta__ (y se grafica en el eje _y_) y a la variable independiente también se la conoce como __variable predictora__ o __explicativa__.  

A diferencia del análisis de correlación, en el análisis de regresión se asume una __relación causa-efecto__ en la que las variaciones en la variable predictora causan cambios en la variable respuesta.  

#### __Ejercicio__  
Escribir ejemplos de posibles relaciones causa-efecto entre dos variables, indicando cuál es la variable respuesta y cuál la predictora.

## 3.3.1.Fundamentos de la Regresión Lineal Simple
#### Objetivos  
__Formalizar el modelo y los supuestos de la regresión lineal simple__  

Una __regresión lineal simple__ modela el efecto de una variable predictora continua sobre una variable de respuesta continua. La __ecuación de regresión__ resultante se puede representar gráficamente como una __línea de regresión__, que representa los valores esperados de la variable de respuesta para todos los valores de la variable predictora.

En la regresión lineal simple, la relación funcional entre la variable dependiente (_y_) y la independiente (_x_) se representa:  
$$\mu_y = \alpha + \beta x$$

donde:  

> $\mu_y$: es la media poblacional de _y_ para cualquier valor de _x_,    
> $\alpha$: es el __intercepto__ y  
> $\beta$: es la __pendiente__.  

Esta ecuación describe una línea recta.  En forma estadística esta ecuación toma la forma:  
$$y_i = \alpha + \beta x + e_i$$  
donde el término $e_i$ indica la desviación aleatoria o __residual__ del valor de $y_i$ con respecto al valor esperado $\mu_y$.  

### Objetivos del Análisis de Regresión  

1. Estimar la ecuación de regresión mediante estimadores de $\alpha$ (_a_) y $\beta$ (_b_) a partir de una muestra y generar intervalos de confianza para los mismos.  
2. Usar la ecuación de regresión para predecir valores de _y_ a partir de valores de _x_.  
3. Estimar que tanto está la variable dependiente controlada por la variable independiente, en otras palabras que tanto la variación en _y_ se explica por la variación en _x_.

### Supuestos del Análisis de Regresión  
Como en todo análisis estadístico paramétrico, la regresión lineal simple posee algunos supuestos:  

1. Las observaciones son independientes, lo cual implica que cada sujeto en una muestra solo se mide una vez: no puede haber pseudoreplicación.    
2. Se asume (aunque la visualización no lo muestre) que la relación entre las dos variables es lineal.  
3. Los residuales ($e_i$) alrededor de la línea de regresión tienen una distribución normal estándar ($\mu = 0$).  
4. La varianza de los residuales es igual para todos los valores de _x_ de los datos.  Esto es equivalente a la homogeneidad de varianza en el ANOVA.  

\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 3.3.2.Parámetros de la Regresión
#### Objetivos
__Calcular y probar hipótesis sobre los parámetros de la regresión lineal simple__ 



\  

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 3.3.3.Pruebas de Hipótesis para la Regresión

 

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 3.3.4.Predicción de y a partir de x

 

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 3.3.5.Otras Técnicas de Regresión

  

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)
